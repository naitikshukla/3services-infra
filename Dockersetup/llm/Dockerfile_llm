# Use a base image with specific CUDA version installed
FROM nvidia/cuda:11.0-base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    python3 \
    python3-venv \
    python3-pip \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements.txt file
COPY requirements_llm.txt /app/requirements.txt

# Set up virtual environment
RUN python3 -m venv venv
RUN /bin/bash -c "source venv/bin/activate && pip install -r requirements.txt"

# Copy LLM service files
COPY llm_service.py /app/llm_service.py

# Install OLLAMA serve and other dependencies
RUN pip3 install ollama-serve

# Expose port 11434
EXPOSE 11434

# Command to run the service
CMD ["bash", "-c", "source venv/bin/activate && python llm_service.py"]